{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Договоренности о функциях потерь:\n",
        "1. Для регрессии reg: linear\n",
        "2. Двоичная классифкация reg: logistic - выход категория целевого объекта; binary: logistic - вероятность положительного класса  "
      ],
      "metadata": {
        "id": "2CR6P92YmV2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "class_data = pd.read_csv(\"classification_data.csv\")\n",
        "X, y = class_data.iloc[:,:-1], class_data.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
        "test_size=0.2, random_state=123)\n",
        "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
        "xg_cl.fit(X_train, y_train)\n",
        "preds = xg_cl.predict(X_test)\n",
        "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
        "print(\"accuracy: %f\" % (accuracy)) #accuracy: 0.78333\n"
      ],
      "metadata": {
        "id": "Nyi9FSp_pCxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross-validation in XGBoost example\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "churn_data = pd.read_csv(\"classification_data.csv\")\n",
        "churn_dmatrix = xgb.DMatrix(data=churn_data.iloc[:,:-1], label=churn_data.month_5_still_here) # data = X, label = y\n",
        "params={\"objective\":\"binary:logistic\",\"max_depth\":4}\n",
        "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4, num_boost_round=10, metrics=\"error\", as_pandas=True)\n",
        "#данные, параметры, кол-во фолдов в cross-validation, кол-во деревьев, \"error\" - преобразуется в accuracy через 1 - \"_error-mean\"\n",
        "print(\"Accuracy: %f\" %((1-cv_results[\"test-error-mean\"]).iloc[-1]))\n",
        "# у такого подхода есть cross-validation оценка"
      ],
      "metadata": {
        "id": "4IOro3x2pNht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#регрессионная модель с деревьями с помощью API совместимого с scikit-learn\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "boston_data = pd.read_csv(\"boston_housing.csv\")\n",
        "X, y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:linear', n_estimators=10, seed=123)\n",
        "xg_reg.fit(X_train, y_train)\n",
        "preds = xg_reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "metadata": {
        "id": "i5uvBJwcmx3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#использование только API XGBoost\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "boston_data = pd.read_csv(\"boston_housing.csv\")\n",
        "X, y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "DM_train = xgb.DMatrix(data=X_train,label=y_train) #преобразование набора в объекты DMatrix\n",
        "DM_test = xgb.DMatrix(data=X_test,label=y_test)\n",
        "params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"} #создаем словарь параметров, явно указывающий базового учащегося\n",
        "#\"booster\":\"gblinear\" - linear learner\n",
        "xg_reg = xgb.train(params = params, dtrain=DM_train, num_boost_round=10)\n",
        "preds = xg_reg.predict(DM_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "metadata": {
        "id": "ju_4XF5Rmv-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры регуляризации в XGBoost\n",
        "1. gamma (для деревьев) - чем больше тем меньше разделений  \n",
        "2. alpha - L1 регуляризация для весов листьев, многие веса идут к нулю\n",
        "3. lambda - L2 для листев"
      ],
      "metadata": {
        "id": "vpPf7C8sqRyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "boston_data = pd.read_csv(\"boston_data.csv\")\n",
        "X,y = boston_data.iloc[:,:-1],boston_data.iloc[:,-1]\n",
        "boston_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "params={\"objective\":\"reg:linear\", \"max_depth\":4}\n",
        "l1_params = [1,10,100]\n",
        "rmses_l1=[]\n",
        "for reg in l1_params:\n",
        "  params[\"alpha\"] = reg\n",
        "  cv_results = xgb.cv(dtrain=boston_dmatrix, params=params, nfold=4,\n",
        "  num_boost_round=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "  rmses_l1.append(cv_results[\"test-rmse-mean\"].tail(1).values[0])\n",
        "print(\"Best rmse as a function of l1:\")\n",
        "print(pd.DataFrame(list(zip(l1_params,rmses_l1)), columns=[\"l1\", \"rmse\"]))"
      ],
      "metadata": {
        "id": "0kbz1nYer1lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# отрисовка ка каждого дерева\n",
        "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
        "\n",
        "# Plot the first tree\n",
        "xgb.plot_tree(xg_reg, num_trees=0)\n",
        "plt.show()\n",
        "\n",
        "# Plot the fifth tree\n",
        "xgb.plot_tree(xg_reg, num_trees=1)\n",
        "plt.show()\n",
        "\n",
        "# Plot the last tree sideways\n",
        "xgb.plot_tree(xg_reg, num_trees=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2z9fUu3YmKbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# гистограмма важности признака (для tree) - кол-во раз когда признак был в разбиении\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
        "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
        "\n",
        "# Plot the feature importances\n",
        "xgb.plot_importance(xg_reg)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fpTIGbbRpV0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ранняя остновка\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
        "# Perform cross-validation with early stopping: cv_results\n",
        "cv_results = xgb.cv(dtrain = housing_dmatrix, params = params, seed = 123, metrics = 'rmse', early_stopping_rounds = 10,  num_boost_round=50, nfold = 3, as_pandas = True)\n",
        "# Print cv_results\n",
        "print(cv_results)"
      ],
      "metadata": {
        "id": "vq5Te4Wa4nCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При более высоких значениях \"eta\" (learning rate) штрафные веса признаков становятся более значительными, что приводит к гораздо более сильной регуляризации.\n",
        "\n",
        "colsample_bytree - от 0 до 1 доля признаков при каждом разбиении"
      ],
      "metadata": {
        "id": "i-jUifsr5Yrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
        "\n",
        "eta_vals = [0.001, 0.01, 0.1]\n",
        "best_rmse = []\n",
        "\n",
        "for curr_val in eta_vals:\n",
        "    params[\"eta\"] = curr_val\n",
        "    cv_results = xgb.cv(seed = 123, metrics = 'rmse', params = params, dtrain = housing_dmatrix, early_stopping_rounds = 5,  num_boost_round=10, nfold = 3, as_pandas = True)\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
      ],
      "metadata": {
        "id": "CRvBefAG5azY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#лучшие модификации для colsample_bytree, learning_rate и max_depth\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "housing_data = pd.read_csv(\"ames_housing_trimmed_processed.csv\")\n",
        "X,y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "untuned_params={\"objective\":\"reg:linear\"}\n",
        "untuned_cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=untuned_params,nfold=4, metrics=\"rmse\", as_pandas=True,seed=123)\n",
        "print(\"Untuned rmse: %f\" %((untuned_cv_results_rmse[\"test-rmse-mean\"]).tail(1)))"
      ],
      "metadata": {
        "id": "zHCCGlTXtD9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#еще лучше количество деревьев 200\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "housing_data = pd.read_csv(\"ames_housing_trimmed_processed.csv\")\n",
        "X,y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "tuned_params = {\"objective\":\"reg:linear\", 'colsample_bytree': 0.3, 'learning_rate': 0.1,'max_depth': 5}\n",
        "tuned_cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=tuned_params, nfold=4, num_boost_round=200, metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "print(\"Tuned rmse: %f\" %((tuned_cv_results_rmse[\"test-rmse-mean\"]).tail(1)))"
      ],
      "metadata": {
        "id": "2Sl_LPE9txJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настраиваемые параметры будут отличаться в зависимости от базового алгоритма\n",
        "Для дерева:\n",
        "1. learning rate\n",
        "2. gamma\n",
        "3. lambda\n",
        "4. alpha\n",
        "5. max_depth\n",
        "6. subsample\n",
        "7. colsample_bytree\n",
        "\n",
        "Для линейного базового алгоритма:\n",
        "1. lambda\n",
        "2. alpha  \n",
        "3. lambda_bias"
      ],
      "metadata": {
        "id": "9c2xWwy8urIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#поиск по сетке\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "housing_data = pd.read_csv(\"ames_housing_trimmed_processed.csv\")\n",
        "X, y = housing_data[housing_data.columns.tolist()[:-1]], housing_data[housing_data.columns.tolist()[-1]]\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y) # зачем\n",
        "gbm_param_grid = {'learning_rate': [0.01,0.1,0.5,0.9], 'n_estimators': [200], 'subsample': [0.3, 0.5, 0.9]}\n",
        "gbm = xgb.XGBRegressor()\n",
        "grid_mse = GridSearchCV(estimator=gbm,param_grid=gbm_param_grid, scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
        "grid_mse.fit(X, y)\n",
        "print(\"Best parameters found: \", grid_mse.best_params_)\n",
        "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
      ],
      "metadata": {
        "id": "k35LIj0f2Sui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#случайный поиск\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "housing_data = pd.read_csv(\"ames_housing_trimmed_processed.csv\")\n",
        "X,y = housing_data[housing_data.columns.tolist()[:-1]],\n",
        "housing_data[housing_data.columns.tolist()[-1]]\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y) # зачем\n",
        "gbm_param_grid = {'learning_rate': np.arange(0.05,1.05,.05), 'n_estimators': [200], 'subsample': np.arange(0.05,1.05,.05)}\n",
        "gbm = xgb.XGBRegressor()\n",
        "randomized_mse = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid, n_iter=25, scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
        "randomized_mse.fit(X, y) # param_distributions - отличие\n",
        "print(\"Best parameters found: \",randomized_mse.best_params_)\n",
        "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
      ],
      "metadata": {
        "id": "l9P3fXm32dKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#делаем pipeline для случайного леса\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\",\"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
        "data = pd.read_csv(\"boston_housing.csv\", names=names)\n",
        "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
        "rf_pipeline = Pipeline[(\"st_scaler\", StandardScaler()), (\"rf_model\", RandomForestRegressor())]\n",
        "scores = cross_val_score(rf_pipeline,X,y, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
        "print(\"Final RMSE:\", final_avg_rmse)"
      ],
      "metadata": {
        "id": "SnUt8mhn2QHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#делаем pipeline для XGBoost через Scikit-learn API\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\",\"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
        "data = pd.read_csv(\"boston_housing.csv\",names=names)\n",
        "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
        "xgb_pipeline = Pipeline[(\"st_scaler\", StandardScaler()), (\"xgb_model\",xgb.XGBRegressor())]\n",
        "scores = cross_val_score(xgb_pipeline, X, y, scoring=\"neg_mean_squared_error\",cv=10)\n",
        "final_avg_rmse = np.mean(np.sqrt(np.abs(scores)))\n",
        "print(\"Final XGB RMSE:\", final_avg_rmse)"
      ],
      "metadata": {
        "id": "U6OZLj_p5tu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# практика с векторизацией\n",
        "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
        "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n",
        "xgb_pipeline = Pipeline(steps)\n",
        "cross_val_scores = cross_val_score(xgb_pipeline, X.to_dict('records'), y, scoring = 'neg_mean_squared_error', cv = 10)\n",
        "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
      ],
      "metadata": {
        "id": "0pLPqmczXCfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Настройка гиперпараметров xgboost в pipeline\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "names = [\"crime\",\"zone\",\"industry\",\"charles\",\"no\",\"rooms\",\"age\",\"distance\",\"radial\",\"tax\",\"pupil\",\"aam\",\"lower\",\"med_price\"]\n",
        "data = pd.read_csv(\"boston_housing.csv\", names=names)\n",
        "X, y = data.iloc[:,:-1],data.iloc[:,-1]\n",
        "xgb_pipeline = Pipeline[(\"st_scaler\", StandardScaler()), (\"xgb_model\", xgb.XGBRegressor())]\n",
        "gbm_param_grid = {'xgb_model__subsample': np.arange(.05, 1, .05), 'xgb_model__max_depth': np.arange(3,20,1), 'xgb_model__colsample_bytree': np.arange(.1,1.05,.05) }\n",
        "randomized_neg_mse = RandomizedSearchCV(estimator=xgb_pipeline, param_distributions=gbm_param_grid, n_iter=10, scoring='neg_mean_squared_error', cv=4)\n",
        "randomized_neg_mse.fit(X, y)\n",
        "print(\"Best rmse: \", np.sqrt(np.abs(randomized_neg_mse.best_score_)))\n",
        "print(\"Best model: \", randomized_neg_mse.best_estimator_)"
      ],
      "metadata": {
        "id": "7GvYrPQp8c6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование данных"
      ],
      "metadata": {
        "id": "q9Js5sYZMN2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "df.LotFrontage = df.LotFrontage.fillna(0) # заполение NaN нулями\n",
        "categorical_mask = (df.dtypes == 'object') # создание маски где тип object\n",
        "\n",
        "categorical_columns = df.columns[categorical_mask].tolist() # получаем список категорильных столбцов\n",
        "print(df[categorical_columns].head())\n",
        "\n",
        "le = LabelEncoder() # три катеогории - 0, 1, 2\n",
        "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
        "print(df[categorical_columns].head())\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "df_encoded = ohe.fit_transform(df)\n",
        "\n",
        "#или все проще\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "df_dict = df.to_dict('records')\n",
        "dv = DictVectorizer(sparse=False)\n",
        "df_encoded = dv.fit_transform(df_dict)\n",
        "print(dv.vocabulary_)\n",
        "\n",
        "#суем в пайплайн\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "X.LotFrontage = X.LotFrontage.fillna(0)\n",
        "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)), (\"xgb_model\", xgb.XGBRegressor())]\n",
        "xgb_pipeline = Pipeline(steps)\n",
        "xgb_pipeline.fit(X.to_dict(\"records\"), y)"
      ],
      "metadata": {
        "id": "MRPlq-XfMQJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование признаков c sklearn_pandas (конспект)"
      ],
      "metadata": {
        "id": "6SYfR-jN67NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "nulls_per_column = X.isnull().sum()\n",
        "print(nulls_per_column)\n",
        "\n",
        "categorical_feature_mask = X.dtypes == object\n",
        "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
        "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
        "\n",
        "numeric_imputation_mapper = DataFrameMapper([([numeric_feature], SimpleImputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
        "                                            input_df=True, df_out=True)\n",
        "categorical_imputation_mapper = DataFrameMapper([(category_feature, SimpleImputer()) for category_feature in categorical_columns],\n",
        "                                                input_df=True, df_out=True)\n",
        "\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "numeric_categorical_union = FeatureUnion([(\"num_mapper\", numeric_imputation_mapper), (\"cat_mapper\", categorical_imputation_mapper)])\n",
        "\n",
        "pipeline = Pipeline([(\"featureunion\", numeric_categorical_union),\n",
        "                     (\"dictifier\", Dictifier()),\n",
        "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
        "                     (\"clf\", xgb.XGBClassifier(max_depth=3))])\n",
        "\n",
        "cross_val_scores = cross_val_score(pipeline, X, y, scoring=\"roc_auc\", cv=3)\n",
        "print(\"3-fold AUC: \", np.mean(cross_val_scores))\n",
        "\n",
        "gbm_param_grid = {\n",
        "    'clf__learning_rate': np.arange(0.05, 1, 0.05),\n",
        "    'clf__max_depth': np.arange(3, 10, 1),\n",
        "    'clf__n_estimators': np.arange(50, 200, 50)}\n",
        "\n",
        "randomized_roc_auc = RandomizedSearchCV(estimator=pipeline, param_distributions=gbm_param_grid, n_iter=2, scoring='roc_auc', cv=2, verbose=1)\n",
        "\n",
        "randomized_roc_auc.fit(X, y)\n",
        "\n",
        "print(randomized_roc_auc.best_score_)\n",
        "print(randomized_roc_auc.best_estimator_)"
      ],
      "metadata": {
        "id": "88v5Vw4H9euJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}