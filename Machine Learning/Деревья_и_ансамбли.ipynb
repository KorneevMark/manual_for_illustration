{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "D877ilMyEq1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision-Tree for Classification"
      ],
      "metadata": {
        "id": "NYsTH65uNIZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
        "dt = DecisionTreeClassifier(criterion='gini', random_state=1, max_depth=2)\n",
        "dt.fit(X_train,y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "iUZx8L_mNUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204910fd-f09d-4439-cb2b-1814fb7436d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision-Tree for Regression"
      ],
      "metadata": {
        "id": "JBy9YV7LT2Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=3)\n",
        "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.1, random_state=3)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "mse_dt = MSE(y_test, y_pred)\n",
        "rmse_dt = mse_dt**(1/2)\n",
        "print(rmse_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g6rIf3z9Y4X",
        "outputId": "39ec8e48-f265-442b-ce61-9b1c22519b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55.512621799818966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Учитывая, что ошибка train меньше, чем CV-ошибка, можем сделать вывод, что dt переобучается на тренировочном наборе и что он страдает от высокой дисперсии.\n",
        "\n",
        "Обратите внимание, что ошибки CV и тестового набора примерно равны:\n",
        "*   если CV-ошибка > train-ошибка то высокая дисперсия\n",
        "*   если СV-ошибка = train-ошибки но выше чем желаемая - высокое смещение\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s-LK-RBU-Dnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=123)\n",
        "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=123)\n",
        "\n",
        "MSE_CV = - cross_val_score(dt, X_train, y_train, cv= 10, scoring='neg_mean_squared_error', n_jobs = -1)\n",
        "dt.fit(X_train, y_train)\n",
        "y_predict_train = dt.predict(X_train)\n",
        "y_predict_test = dt.predict(X_test)\n",
        "\n",
        "print('CV MSE: {:.2f}'.format(MSE_CV.mean())) #20.51 CV MSE\n",
        "print('Train MSE: {:.2f}'.format(MSE(y_train, y_predict_train))) #15.30  Training set MSE\n",
        "print('Test MSE: {:.2f}'.format(MSE(y_test, y_predict_test))) #20.92 Test set MSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5tl0iDZ92EW",
        "outputId": "ac5bd8ed-e705-431f-be94-0bddcb26d4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV MSE: 4205.85\n",
            "Train MSE: 3253.94\n",
            "Test MSE: 4193.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простое голосование в ансамбле"
      ],
      "metadata": {
        "id": "lP7RoHxWwAzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 1, shuffle = True)\n",
        "lr = LogisticRegression(random_state=123)\n",
        "knn = KNN()\n",
        "dt = DecisionTreeClassifier(random_state=123)\n",
        "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
        "\n",
        "for clf_name, clf in classifiers:\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred))) #Logistic Regression: 0.947\n",
        "\n",
        "vc = VotingClassifier(estimators=classifiers)\n",
        "vc.fit(X_train, y_train)\n",
        "y_pred = vc.predict(X_test)\n",
        "print('Voting Classifier: {}'.format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWymu7ne-wXL",
        "outputId": "03cd0956-f30e-40b8-94f2-51ffed28aa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression : 0.978\n",
            "K Nearest Neighbours : 0.978\n",
            "Classification Tree : 0.956\n",
            "Voting Classifier: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Усреднение (мягкое голосование) - для регрессии и классификации (вероятности)\n",
        "* Голосование (мажоритарное голосование) - для классификации"
      ],
      "metadata": {
        "id": "Pq75Zq0eBdlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier # класс\n",
        "clf_knn = KNeighborsClassifier(5)\n",
        "clf_dt = DecisionTreeClassifier()\n",
        "clf_lr = LogisticRegression()\n",
        "\n",
        "clf_voting = VotingClassifier(estimators=[('knn', clf_knn), ('dt', clf_dt), ('lr', clf_lr)])\n",
        "clf_voting.fit(X_train, y_train)\n",
        "y_pred = clf_voting.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:0.3f}\".format(acc))"
      ],
      "metadata": {
        "id": "eqYT98216ZPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier # Averaging Classifier\n",
        "clf_voting = VotingClassifier(estimators=[('label1', clf_1), ('label2', clf_2), ... ('labelN', clf_N)],\n",
        "                              voting='soft', #Значение по умолчанию — «hard»\n",
        "                              weights=[w_1, w_2, ..., w_N])\n",
        "\n",
        "from sklearn.ensemble import VotingRegressor # Averaging Regressor\n",
        "reg_voting = VotingRegressor(estimators=[('label1', reg_1), ('label2', reg_2), ... ('labelN', reg_N)],\n",
        "                             weights=[w_1, w_2, ..., w_N])\n",
        "#можем передать необязательные веса параметров, которые определяют вес для каждого из оценщиков"
      ],
      "metadata": {
        "id": "FCLn22FbCG2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# пример\n",
        "clf_knn = KNeighborsClassifier(5)\n",
        "clf_dt = DecisionTreeClassifier()\n",
        "clf_lr = LogisticRegression() # LogisticRegression(class_weight = 'balanced')\n",
        "clf_voting = VotingClassifier(estimators=[\n",
        "                               ('knn', clf_knn),\n",
        "                               ('dt', clf_dt),\n",
        "                               ('lr', clf_lr)], voting='soft', weights=[1, 2, 1])\n",
        "#clf_lr = LogisticRegression(class_weight='balanced')\n",
        "#clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
        "#clf_svm = SVC(probability=True, class_weight='balanced', random_state=500) - вероятности"
      ],
      "metadata": {
        "id": "BF9_lV5_HUOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging"
      ],
      "metadata": {
        "id": "oOVqfD2QyghM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# хотят слабых моделей\n",
        "model = DecisionTreeClassifier(max_depth=3) # огр-ие глубины\n",
        "model = LogisticRegression(max_iter=50, C=100.0) # кол-во итерация и регуляризация\n",
        "model = LinearRegression()\n",
        "#Линейная регрессия, как и логистическая регрессия, предполагает, что выходные данные\n",
        "#являются линейной функцией входных признаков. Кроме того, он опирается на независимость этих функций"
      ],
      "metadata": {
        "id": "Bhhi73htQwMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему bagging является полезной техникой? Во-первых, это помогает уменьшить дисперсию, так как выборка действительно случайна. Bias также может быть уменьшена, поскольку мы используем голосование или усреднение для объединения моделей. Из-за большого количества используемых оценщиков bagging обеспечивает стабильность и надежность. Однако bagging требует больших вычислительных ресурсов с точки зрения пространства и времени."
      ],
      "metadata": {
        "id": "vta4IKoxXwxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры по улучшению bagging\n",
        "\n",
        "* base_estimator\n",
        "* n_estimators - чем больше тем лучше\n",
        "* oob_score (вызов est_bag.oob_score_)\n",
        "\n",
        "* max_samples (подвыборка)\n",
        "* max_features (class sqrt(признаки), рег признаки/3)\n",
        "* bootstrap (по дефолту True, тогда max_sample = 1; False max_sample < 1)"
      ],
      "metadata": {
        "id": "7Ls77ET-az-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)\n",
        "dt = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=123)\n",
        "\n",
        "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, n_jobs=-1)\n",
        "bc.fit(X_train, y_train)\n",
        "y_pred = bc.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy of Bagging Classifier: {:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "EW62T-KPyfp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7f2853-c722-4609-ca20-44eef92a03f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Bagging Classifier: 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# out-of-bag\n",
        "dt = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=123)\n",
        "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1)\n",
        "bc.fit(X_train, y_train)\n",
        "y_pred = bc.predict(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "oob_accuracy = bc.oob_score_\n",
        "print('Test set accuracy: {:.3f}'.format(test_accuracy)) # 0.936\n",
        "print('OOB accuracy: {:.3f}'.format(oob_accuracy)) # 0.925\n",
        "# Однако это часто ниже, чем фактическая производительность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DElCK5wkBlzp",
        "outputId": "0203096b-56e1-4714-be4b-6bfa16d1d0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy: 0.956\n",
            "OOB accuracy: 0.933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "lOe-awxMFWqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_auto = pd.read_csv('/content/auto.csv')\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "X_auto, y_auto = data_auto.drop(columns = ['mpg', 'origin']), data_auto['mpg']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_auto, y_auto, test_size=0.3, random_state=1)\n",
        "rf = RandomForestRegressor(n_estimators=400, min_samples_leaf=0.12, random_state=1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dolsx9J-FTSR",
        "outputId": "10e3cfb7-364a-4faa-dcc3-390f7ca031e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set RMSE of rf: 3.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree-specific parameters:\n",
        "* n_estimators\n",
        "* max_features\n",
        "* oob_score\n",
        "* max_depth - глубина\n",
        "* min_samples_split - , минимальное количество образцов, необходимых для разделения узла\n",
        "* min_samples_leaf - минимальное количество образцов, необходимых для листового узла\n",
        "* class_weight ( “balanced” ) - вес класса (справляется с несбалансированными классами)"
      ],
      "metadata": {
        "id": "mYSMZv-pdfZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если обучается метод основанный на дереве то можно получить оуенку значимости признака (как узлы дерева используют его)"
      ],
      "metadata": {
        "id": "My7bn8XP6LB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "importances_rf = pd.Series(rf.feature_importances_, index = X_auto.columns)\n",
        "sorted_importances_rf = importances_rf.sort_values()\n",
        "sorted_importances_rf.plot(kind='barh', color='lightgreen'); plt.show() #% вес признака в обучении и прогнозировании\n",
        "# удаленный категориальный признак не влияет"
      ],
      "metadata": {
        "id": "OpspPiP96deA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "5c0c966e-a18c-457c-bb92-40305151f728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost"
      ],
      "metadata": {
        "id": "SHJ7Ucuy7XZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoostClassifier:\n",
        "\n",
        "* base_estimator - по дефолту дерево с глубиной 1\n",
        "\n",
        "* n_estimators - по дефолту 50 (Если есть идеальное соответствие или оценщик с погрешностью более 50%, оценщики больше не строятся)\n",
        "\n",
        "* learning_rate - показывает, какой вклад вносит каждый оценщик в ансамбль. По умолчанию это 1.0. Существует компромисс между количеством оценщиков и скоростью обучения."
      ],
      "metadata": {
        "id": "k47DYlyZXh2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoostRegressor\n",
        "* base_estimator - по дефолту Decision Tree (max_depth=3)\n",
        "\n",
        "* loss: linear (default), square, exponentia\n",
        "\n",
        "Есть параметр потерь, который является функцией, используемой для обновления весов (умолчанию он линейный)"
      ],
      "metadata": {
        "id": "xm1swTX5YwyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#у каждого предиктора появляется вес альфа\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X, y = X[:100], y[:100]\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier #AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
        "dt = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
        "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
        "adb_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
        "adb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba) #вероятность\n",
        "print('ROC AUC score: {:.2f}'.format(adb_clf_roc_auc_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-z-vVCrIKMI",
        "outputId": "24ce86ee-116a-4fe0-92ce-1c5d3b58ad90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_ada = AdaBoostRegressor(base_estimator, n_estimators, learning_ rate, loss)\n",
        "\n",
        "reg_lm = LinearRegression()\n",
        "reg_ada = AdaBoostRegressor(n_estimators = 12, loss = 'linear', random_state=500, base_estimator = reg_lm)\n",
        "reg_ada.fit(X_train, y_train)\n",
        "\n",
        "pred = reg_ada.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "print('RMSE: {:.3f}'.format(rmse))"
      ],
      "metadata": {
        "id": "zlaz7-5mYy23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "fDsCvhSN_puO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь не указываем base_estimator, так как Gradient Boosting реализован и оптимизирован с помощью деревьев регрессии\n",
        "\n",
        "n_estimators (Default: 100)\n",
        "\n",
        "learning_rate (Default: 0.1)\n",
        "\n",
        "max_depth (Default: 3)\n",
        "\n",
        "min_samples_split (для разделения)\n",
        "\n",
        "min_samples_leaf (для листа)\n",
        "\n",
        "max_features (рекомендуют все)"
      ],
      "metadata": {
        "id": "Ws1eSlYSoXpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_auto,y_auto, test_size=0.3, random_state=1)\n",
        "\n",
        "gbt = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=1)\n",
        "gbt.fit(X_train, y_train)\n",
        "y_pred = gbt.predict(X_test)\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "print('Test set RMSE: {:.2f}'.format(rmse_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvCQSAvtKPY-",
        "outputId": "59f4e610-7abc-41a3-ddf5-e3a56ab3bb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set RMSE: 4.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient Boosting"
      ],
      "metadata": {
        "id": "CebZ5q8pGA_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "SEED = 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_auto,y_auto, test_size=0.3, random_state=SEED)\n",
        "# Instantiate a stochastic GradientBoostingRegressor 'sgbt'\n",
        "sgbt = GradientBoostingRegressor(max_depth=1, subsample=0.8, max_features=0.2, n_estimators=300, random_state=SEED) #параметр subsample = 0.8\n",
        "sgbt.fit(X_train, y_train)\n",
        "y_pred = sgbt.predict(X_test)\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "print('Test set RMSE: {:.2f}'.format(rmse_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ks2JG6LKZO",
        "outputId": "6fbb5124-b9e4-4def-a47f-e1420bdde413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set RMSE: 4.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters of a CART"
      ],
      "metadata": {
        "id": "MW3K0lxhJynp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=SEED) #print(dt.get_params())\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params_dt = {'max_depth': [3, 4, 5, 6], 'min_samples_leaf': [0.04, 0.06, 0.08], 'max_features': [0.2, 0.4,0.6, 0.8]}\n",
        "grid_dt = GridSearchCV(estimator=dt, param_grid=params_dt, scoring='accuracy', cv=10, n_jobs=-1)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "best_hyperparams = grid_dt.best_params_\n",
        "print('Best hyerparameters:\\n', best_hyperparams) #Best hyerparameters: {'max_depth': 3,'max_features': 0.4, 'min_samples_leaf': 0.06}\n",
        "best_CV_score = grid_dt.best_score_\n",
        "print('Best CV accuracy'.format(best_CV_score)) #Best CV accuracy: 0.938\n",
        "\n",
        "best_model = grid_dt.best_estimator_\n",
        "test_acc = best_model.score(X_test,y_test)\n",
        "print(\"Test set accuracy of best model: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "MEaTDzzDOUc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning an RF's Hyperparameters"
      ],
      "metadata": {
        "id": "gbNf6hxqWt01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(random_state= SEED)\n",
        "rf.get_params()\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params_rf = {'n_estimators': [300, 400, 500],'max_depth': [4, 6, 8],'min_samples_leaf': [0.1, 0.2], 'max_features': ['log2', 'sqrt']}\n",
        "grid_rf = GridSearchCV(estimator=rf, param_grid=params_rf, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "best_hyperparams = grid_rf.best_params_\n",
        "print('Best hyperparameters:\\n', best_hyperparams) #Best hyperparameters: {'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 0.1, 'n_estimators': 400}\n",
        "best_model = grid_rf.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
      ],
      "metadata": {
        "id": "-mEgM--bRVUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "Tob6-TOWuW4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost использует **параллельную обработку** для обучения каждого оценщика, тем самым ускоряя обработку"
      ],
      "metadata": {
        "id": "Tq3ZmrDql1vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb # (можно XGBRegressor)\n",
        "clf_xgb = xgb.XGBClassifier(n_estimators=100, learning_rate=None, max_depth=None, random_state)\n",
        "clg_xgb.fit(X_train, y_train) # learning_rate и max_depth не имеют значения по умолчанию (надо указывать)\n",
        "pred = clf_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "kcr6DZUuZ2nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM"
      ],
      "metadata": {
        "id": "_ab2cdiLv4JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb # можно LGBMRegressor\n",
        "clf_lgb = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state)\n",
        "clf_lgb.fit(X_train, y_train) # максимальная глубина, которая по умолчанию отрицательна\n",
        "# что означает отсутствие ограничений. Следовательно, мы должны указать его значение, если требуется предел.\n",
        "pred = clf_lgb.predict(X_test) # лепи дальше sklearn"
      ],
      "metadata": {
        "id": "Kgxp9NHGv7Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "revWgf_TycRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost as cb #(CatBoostClassifier и CatBoostRegressor)\n",
        "clf_cat = cb.CatBoostClassifier(n_estimators=None, learning_rate=None, max_depth=None, random_state)\n",
        "clf_cat.fit(X_train, y_train)\n",
        "pred = clf_cat.predict(X_test)\n",
        "#CatBoost имеет встроенную возможность обработки категориальных функций, поэтому вам не нужно\n",
        "#выполнять предварительную обработку самостоятельно"
      ],
      "metadata": {
        "id": "o66etaNuyfMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# примеры\n",
        "reg_xgb = xgb.XGBRegressor(max_depth = 3, learning_rate = 0.1, n_estimators = 100, n_jobs=2, objective='reg:squarederror', random_state=500)\n",
        "reg_xgb.fit(X_train, y_train)\n",
        "\n",
        "reg_lgb = lgb.LGBMRegressor(max_depth = 3, learning_rate = 0.1, n_estimators = 100, objective='mean_squared_error', seed=500)\n",
        "reg_lgb.fit(X_train, y_train)\n",
        "\n",
        "pred_xgb = reg_xgb.predict(X_test)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, pred_xgb))\n",
        "pred_lgb = reg_lgb.predict(X_test)\n",
        "rmse_lgb = np.sqrt(mean_squared_error(y_test, pred_lgb))\n",
        "print('Extreme: {:.3f}, Light: {:.3f}'.format(rmse_xgb, rmse_lgb))\n",
        "\n",
        "import catboost as cb\n",
        "reg_cat = cb.CatBoostRegressor(n_estimators = 100, learning_rate = 0.1, max_depth = 3, random_state=500)\n",
        "reg_cat.fit(X_train, y_train)\n",
        "pred = reg_cat.predict(X_test)\n",
        "\n",
        "rmse_cat = np.sqrt(mean_squared_error(y_test, pred))\n",
        "print('RMSE (CatBoost): {:.3f}'.format(rmse_cat))"
      ],
      "metadata": {
        "id": "ykghVLdi5OBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking"
      ],
      "metadata": {
        "id": "YhhpO4vcIFKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг первый, подготовьте набор данных.\n",
        "\n",
        "Шаг второй: постройте оценки первого уровня.\n",
        "\n",
        "Шаг третий: добавьте прогнозы отдельных оценщиков к исходному набору данных.\n",
        "\n",
        "Шаг четвертый: создайте мета-оценщик второго уровня.\n",
        "\n",
        "И пятый шаг: используйте модель сложенного ансамбля для окончательных прогнозов."
      ],
      "metadata": {
        "id": "5XXxHdBxIycX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking classifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "classifiers = [('clf1', Classifier1(params1)),\n",
        "               ('clf2', Classifier2(params2)),\n",
        "                            ...\n",
        "               ('clfN', ClassifierN(paramsN))]\n",
        "# Instantiate the 2nd-layer classifier\n",
        "clf_meta = ClassifierMeta(paramsMeta)\n",
        "\n",
        "clf_stack = StackingClassifier(estimators=classifiers, final_estimator=clf_meta,\n",
        "                               cv=5, stack_method='predict_proba', passthrough=False)\n",
        "clf_stack.fit(X_train, y_train)\n",
        "pred = clf_stack.predict(X_test)"
      ],
      "metadata": {
        "id": "aYQrKqCNII8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Стекинг регрессора\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "# Instantiate the 1st-layer regressors\n",
        "regressors = [('reg1', Regressor1(params1)),\n",
        "              ('reg2', Regressor2(params2)),\n",
        "                       ...\n",
        "              ('regN', RegressorN(paramsN))]\n",
        "reg_meta = RegressorMeta(paramsMeta)\n",
        "reg_stack = StackingRegressor( estimators=regressors, final_estimator=reg_meta,\n",
        "                              cv=5, passthrough=False)\n",
        "reg_stack.fit(X_train, y_train) # Параметр stack_method отсутствует, так как это регрессор\n",
        "pred = reg_stack.predict(X_test)"
      ],
      "metadata": {
        "id": "SuowNDm_MGyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#пример\n",
        "clf_dt = DecisionTreeClassifier(min_samples_leaf = 3, min_samples_split = 9, random_state=500)\n",
        "clf_dt.fit(X_train, y_train)\n",
        "\n",
        "clf_knn = KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors = 5)\n",
        "clf_knn.fit(X_train, y_train)\n",
        "\n",
        "print('Decision Tree: {:0.4f}'.format(accuracy_score(clf_dt.predict(X_test), y_test)))\n",
        "print('5-Nearest Neighbors: {:0.4f}'.format(accuracy_score(clf_knn.predict(X_test), y_test)))\n",
        "\n",
        "classifiers = [('clf_dt', clf_dt), ('clf_knn', clf_knn)]\n",
        "\n",
        "clf_meta = LogisticRegression()\n",
        "\n",
        "clf_stack = StackingClassifier(estimators=classifiers, final_estimator=clf_meta,\n",
        "                               passthrough=False, stack_method='predict_proba')\n",
        "clf_stack.fit(X_train, y_train)\n",
        "pred_stack = clf_stack.predict(X_test)\n",
        "print('Accuracy: {:0.4f}'.format(accuracy_score(pred_stack, y_test)))"
      ],
      "metadata": {
        "id": "4Qt70l5cd8X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLxtend"
      ],
      "metadata": {
        "id": "hO6txalHccEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Библиотекой Mlxtend позволяет легко создавать ансамбли стекирования"
      ],
      "metadata": {
        "id": "k83J87QyroFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "clf1 = Classifier1(params1)\n",
        "clf2 = Classifier2(params2)\n",
        "...\n",
        "clfN = ClassifierN(paramsN)\n",
        "\n",
        "clf_meta = ClassifierMeta(paramsMeta)\n",
        "\n",
        "clf_stack = StackingClassifier(classifiers=[clf1, clf2, ... clfN], meta_classifier=clf_meta,\n",
        "                               use_probas=False, use_features_in_secondary=False)\n",
        "clf_stack.fit(X_train, y_train)\n",
        "pred = clf_stack.predict(X_test)"
      ],
      "metadata": {
        "id": "Y9xrbZL9rrPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.regressor import StackingRegressor\n",
        "reg1 = Regressor1(params1)\n",
        "reg2 = Regressor2(params2)\n",
        "...\n",
        "regN = RegressorN(paramsN)\n",
        "\n",
        "reg_meta = RegressorMeta(paramsMeta)\n",
        "\n",
        "reg_stack = StackingRegressor(regressors=[reg1, reg2, ... regN], meta_regressor=reg_meta,\n",
        "                              use_features_in_secondary=False)\n",
        "reg_stack.fit(X_train, y_train)\n",
        "pred = reg_stack.predict(X_test)"
      ],
      "metadata": {
        "id": "PMxjiGJXcZ3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# пример\n",
        "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
        "clf_meta = LogisticRegression()\n",
        "clf_stack = StackingClassifier(classifiers=[clf_dt, clf_knn], meta_classifier=clf_meta,\n",
        "                               use_probas=True, use_features_in_secondary=False)\n",
        "clf_stack.fit(X_train, y_train)\n",
        "\n",
        "pred_stack = clf_stack.predict(X_test)\n",
        "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred_stack)))\n",
        "\n",
        "# пример\n",
        "reg_dt = DecisionTreeRegressor(min_samples_leaf=11, min_samples_split=33, random_state=500)\n",
        "reg_lr = LinearRegression()\n",
        "reg_ridge = Ridge(random_state=500)\n",
        "\n",
        "reg_meta = LinearRegression()\n",
        "\n",
        "reg_stack = StackingRegressor(regressors=[reg_dt, reg_lr, reg_ridge], meta_regressor=reg_meta)\n",
        "reg_stack.fit(X_train, y_train)\n",
        "\n",
        "pred = reg_stack.predict(X_test)\n",
        "print('MAE: {:.3f}'.format(mean_absolute_error(y_test, pred)))"
      ],
      "metadata": {
        "id": "ID1LJ-ImgeSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}